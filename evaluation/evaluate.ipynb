{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the columns for the validation template\n",
    "columns = [\n",
    "    \"Filename\",\n",
    "    \"Name\",\n",
    "    \"Email\",\n",
    "    \"Phone\",\n",
    "    \"Location\",\n",
    "    \"Summary\",\n",
    "    \"Education Degree\",\n",
    "    \"Education Institution\",\n",
    "    \"Education Year\",\n",
    "    \"Experience Title\",\n",
    "    \"Experience Company\",\n",
    "    \"Experience Duration\",\n",
    "    \"Experience Location\",\n",
    "    \"Experience Description\",\n",
    "    \"Skills\",\n",
    "    \"Project Title\",\n",
    "    \"Project Description\",\n",
    "    \"Certifications\",\n",
    "    \"Languages\",\n",
    "    \"Social Profiles\"\n",
    "]\n",
    "\n",
    "# Directory containing the JSON files\n",
    "directory = \"/home/shtlp_0152/Desktop/project 1/data-ingestion-pipeline/data/standardized_resumes\"\n",
    "\n",
    "# Get all filenames in the directory and sort them alphabetically\n",
    "filenames = sorted([f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and f.endswith(\".json\")])\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "data = {col: [\"\"] * len(filenames) for col in columns}  # Initialize all columns with empty strings\n",
    "data[\"Filename\"] = filenames  # Populate the \"Filename\" column with actual filenames\n",
    "\n",
    "# Function to validate email\n",
    "def validate_email(email):\n",
    "    email_pattern = re.compile(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$')\n",
    "    return bool(email_pattern.match(email))\n",
    "\n",
    "\n",
    "def validate_phone_number(phone_number):\n",
    "    phone_pattern = re.compile(r'''\n",
    "        ^                                # start\n",
    "        (\\(?\\+?\\d{1,3}\\)?[-.\\u2013\\s]*)? # optional country code, allowing – as sep\n",
    "        (\\(?\\d{2,5}\\)?[-.\\u2013\\s]*)?    # optional area code, allowing – as sep\n",
    "        (                                # main number: either…\n",
    "            \\d{5}[-.\\u2013\\s]*\\d{5}      #   5+5 format\n",
    "        |                              # OR\n",
    "            \\d{3}[-.\\u2013\\s]*\\d{3}[-.\\u2013\\s]*\\d{4}  # 3-3-4 format\n",
    "        )\n",
    "        $                                # end\n",
    "    ''', re.VERBOSE)\n",
    "    phone_numbers = re.split(r'\\s*[,/]\\s*', phone_number)\n",
    "    return all(phone_pattern.match(num.strip()) for num in phone_numbers)\n",
    "# Iterate through each file and check for missing or empty fields\n",
    "for i, filename in enumerate(filenames):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "            \n",
    "            # Map JSON fields to the corresponding columns\n",
    "            data[\"Name\"][i] = \"PRESENT\" if json_data.get(\"name\") else \"NULL\"\n",
    "            \n",
    "            # Validate email\n",
    "            email = json_data.get(\"email\", \"\")\n",
    "            if email:\n",
    "                data[\"Email\"][i] = \"PRESENT\" if validate_email(email) else \"INVALID PRESENT\"\n",
    "            else:\n",
    "                data[\"Email\"][i] = \"NULL\"\n",
    "            \n",
    "            # Validate phone\n",
    "            phone = json_data.get(\"phone\", \"\")\n",
    "            if phone:\n",
    "                data[\"Phone\"][i] = \"PRESENT\" if validate_phone_number(phone) else \"INVALID PRESENT\"\n",
    "            else:\n",
    "                data[\"Phone\"][i] = \"NULL\"\n",
    "            \n",
    "            data[\"Location\"][i] = \"PRESENT\" if json_data.get(\"location\") else \"NULL\"\n",
    "            data[\"Summary\"][i] = \"PRESENT\" if json_data.get(\"summary\") else \"NULL\"\n",
    "            \n",
    "            # Check education details\n",
    "            if \"education\" in json_data and json_data[\"education\"]:\n",
    "                education = json_data[\"education\"][0]  # Take the first education entry\n",
    "                data[\"Education Degree\"][i] = \"PRESENT\" if education.get(\"degree\") else \"NULL\"\n",
    "                data[\"Education Institution\"][i] = \"PRESENT\" if education.get(\"institution\") else \"NULL\"\n",
    "                data[\"Education Year\"][i] = \"PRESENT\" if education.get(\"year\") else \"NULL\"\n",
    "            else:\n",
    "                data[\"Education Degree\"][i] = \"NULL\"\n",
    "                data[\"Education Institution\"][i] = \"NULL\"\n",
    "                data[\"Education Year\"][i] = \"NULL\"\n",
    "            \n",
    "            # Check experience details\n",
    "            if \"experience\" in json_data and json_data[\"experience\"]:\n",
    "                experience = json_data[\"experience\"][0]  # Take the first experience entry\n",
    "                data[\"Experience Title\"][i] = \"PRESENT\" if experience.get(\"title\") else \"NULL\"\n",
    "                data[\"Experience Company\"][i] = \"PRESENT\" if experience.get(\"company\") else \"NULL\"\n",
    "                data[\"Experience Duration\"][i] = \"PRESENT\" if experience.get(\"duration\") else \"NULL\"\n",
    "                data[\"Experience Location\"][i] = \"PRESENT\" if experience.get(\"location\") else \"NULL\"\n",
    "                data[\"Experience Description\"][i] = \"PRESENT\" if experience.get(\"description\") else \"NULL\"\n",
    "            else:\n",
    "                data[\"Experience Title\"][i] = \"NULL\"\n",
    "                data[\"Experience Company\"][i] = \"NULL\"\n",
    "                data[\"Experience Duration\"][i] = \"NULL\"\n",
    "                data[\"Experience Location\"][i] = \"NULL\"\n",
    "                data[\"Experience Description\"][i] = \"NULL\"\n",
    "            \n",
    "            # Check other fields\n",
    "            data[\"Skills\"][i] = \"PRESENT\" if json_data.get(\"skills\") else \"NULL\"\n",
    "            if \"projects\" in json_data and json_data[\"projects\"]:\n",
    "                project = json_data[\"projects\"][0]  # Take the first project entry\n",
    "                data[\"Project Title\"][i] = \"PRESENT\" if project.get(\"title\") else \"NULL\"\n",
    "                data[\"Project Description\"][i] = \"PRESENT\" if project.get(\"description\") else \"NULL\"\n",
    "            else:\n",
    "                data[\"Project Title\"][i] = \"NULL\"\n",
    "                data[\"Project Description\"][i] = \"NULL\"\n",
    "            \n",
    "            data[\"Certifications\"][i] = \"PRESENT\" if json_data.get(\"certifications\") else \"NULL\"\n",
    "            data[\"Languages\"][i] = \"PRESENT\" if json_data.get(\"languages\") else \"NULL\"\n",
    "            data[\"Social Profiles\"][i] = \"PRESENT\" if json_data.get(\"social_profiles\") else \"NULL\"\n",
    "    except (json.JSONDecodeError, KeyError):\n",
    "        # If there's an error reading the JSON file, mark all fields as \"NULL\"\n",
    "        for col in columns[1:]:  # Skip \"Filename\"\n",
    "            data[col][i] = \"NULL\"\n",
    "\n",
    "# Create a DataFrame from the data dictionary\n",
    "merged_df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "output_file = \"evaluation_with_validation.xlsx\"\n",
    "merged_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Excel file '{output_file}' created successfully with validation results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total number of rows in the dataset\n",
    "total_rows = len(merged_df)\n",
    "\n",
    "# Count total null values\n",
    "total_nulls = merged_df.apply(lambda col: col.isin([\"NULL\"]).sum()).sum()\n",
    "\n",
    "# Count invalid phone numbers\n",
    "invalid_phone_count = merged_df[\"Phone\"].isin([\"INVALID PRESENT\"]).sum()\n",
    "\n",
    "# Count invalid email addresses\n",
    "invalid_email_count = merged_df[\"Email\"].isin([\"INVALID PRESENT\"]).sum()\n",
    "\n",
    "# Create a detailed null count for specific columns\n",
    "specific_null_counts = {\n",
    "    \"Null Names\": merged_df[\"Name\"].isin([\"NULL\"]).sum(),\n",
    "    \"Null Phone Numbers\": merged_df[\"Phone\"].isin([\"NULL\"]).sum(),  \n",
    "    \"Null Email Addresses\": merged_df[\"Email\"].isin([\"NULL\"]).sum(), \n",
    "    \"Null Locations\": merged_df[\"Location\"].isin([\"NULL\"]).sum(),\n",
    "    \"Null Summaries\": merged_df[\"Summary\"].isin([\"NULL\"]).sum(),\n",
    "    \"Null Skills\": merged_df[\"Skills\"].isin([\"NULL\"]).sum(),\n",
    "    \"Null Education Degrees\": merged_df[\"Education Degree\"].isin([\"NULL\"]).sum(),\n",
    "    \"Null Education Institutions\": merged_df[\"Education Institution\"].isin([\"NULL\"]).sum(),\n",
    "    \"Null Education Years\": merged_df[\"Education Year\"].isin([\"NULL\"]).sum(),\n",
    "    \"Null Experience Titles\": merged_df[\"Experience Title\"].isin([\"NULL\"]).sum(),\n",
    "    \"Null Experience Companies\": merged_df[\"Experience Company\"].isin([\"NULL\"]).sum(),\n",
    "    \"Null Experience Durations\": merged_df[\"Experience Duration\"].isin([\"NULL\"]).sum(),\n",
    "    \"Null Experience Locations\": merged_df[\"Experience Location\"].isin([\"NULL\"]).sum(),\n",
    "    \"Null Experience Descriptions\": merged_df[\"Experience Description\"].isin([\"NULL\"]).sum(),\n",
    "    \"Null Project Titles\": merged_df[\"Project Title\"].isin([\"NULL\"]).sum(),\n",
    "    \"Null Project Descriptions\": merged_df[\"Project Description\"].isin([\"NULL\"]).sum(),\n",
    "    \"Null Certifications\": merged_df[\"Certifications\"].isin([\"NULL\"]).sum(),\n",
    "    \"Null Languages\": merged_df[\"Languages\"].isin([\"NULL\"]).sum(),\n",
    "    \"Null Social Profiles\": merged_df[\"Social Profiles\"].isin([\"NULL\"]).sum(),\n",
    "}\n",
    "\n",
    "# Combine all metrics into a summary DataFrame\n",
    "report_data = {\n",
    "    \"Metric\": [\n",
    "        \"Total Number of Entries\",\n",
    "        \"Total Null Values\",\n",
    "        \"Invalid Phone Numbers\",\n",
    "        \"Invalid Email Addresses\",\n",
    "    ] + list(specific_null_counts.keys()),\n",
    "    \"Details\": [\n",
    "        total_rows,\n",
    "        total_nulls,\n",
    "        invalid_phone_count,\n",
    "        invalid_email_count,\n",
    "    ] + list(specific_null_counts.values()),\n",
    "}\n",
    "report_df = pd.DataFrame(report_data)\n",
    "\n",
    "# Save the report to an Excel file\n",
    "report_file = \"data_quality_report.xlsx\"\n",
    "report_df.to_excel(report_file, index=False)\n",
    "\n",
    "print(f\"Detailed data quality report saved as '{report_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "excel_file = \"data_quality_report.xlsx\"  # Replace with your actual file path\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Extract fields and null values from the Excel file\n",
    "fields = df[\"Metric\"].tolist()  # Assuming the column name is 'Metric'\n",
    "null_values = df[\"Details\"].tolist()  # Assuming the column name is 'Details'\n",
    "\n",
    "# Remove \"Total Null Values\" from the data\n",
    "if \"Total Null Values\" in fields:\n",
    "    index = fields.index(\"Total Null Values\")\n",
    "    fields.pop(index)\n",
    "    null_values.pop(index)\n",
    "\n",
    "# Plot the bar graph\n",
    "plt.figure(figsize=(12, 8)) \n",
    "bars = plt.barh(fields, null_values, color='skyblue') \n",
    "plt.xlabel('Number of Values')\n",
    "plt.title('Values from Resume Field') \n",
    "plt.gca().invert_yaxis() \n",
    "plt.tight_layout()\n",
    "\n",
    "# Add annotations to display the number of null values on each bar\n",
    "for bar, value in zip(bars, null_values):\n",
    "    plt.annotate(str(value), \n",
    "                 xy=(value, bar.get_y() + bar.get_height() / 2), \n",
    "                 xytext=(5, 0),  # Offset the text slightly\n",
    "                 textcoords=\"offset points\", \n",
    "                 va='center', \n",
    "                 ha='left', \n",
    "                 fontsize=10)\n",
    "\n",
    "plt.savefig('values_chart.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Quality Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Kunal Kumar CV.json</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>DEEPALI_JENA_RESUME_1Yr.json</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Anuj Maurya.json</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>HarshYadav.json</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Resume Kushagra Wadhwa.json</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Mohd.Saleem K_ShorthillsAi Resume.json</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Jitin Kumar Vats_SHT Resume 2.json</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>MANEESH KUMAR AGARWAL - Resume 1.json</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Siddhant CV.json</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Sambhav CV.json</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Filename  Quality Score\n",
       "92                      Kunal Kumar CV.json             19\n",
       "56             DEEPALI_JENA_RESUME_1Yr.json             18\n",
       "33                         Anuj Maurya.json             18\n",
       "74                          HarshYadav.json             18\n",
       "146             Resume Kushagra Wadhwa.json             18\n",
       "..                                      ...            ...\n",
       "106  Mohd.Saleem K_ShorthillsAi Resume.json              6\n",
       "86       Jitin Kumar Vats_SHT Resume 2.json              5\n",
       "95    MANEESH KUMAR AGARWAL - Resume 1.json              5\n",
       "174                        Siddhant CV.json              3\n",
       "162                         Sambhav CV.json              0\n",
       "\n",
       "[204 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_score(row):\n",
    "    score = 0\n",
    "    for val in row[1:]:  # skip filename\n",
    "        if val == \"PRESENT\":\n",
    "            score += 1\n",
    "        elif val == \"INVALID PRESENT\":\n",
    "            score -= 1\n",
    "    return score\n",
    "\n",
    "df['Quality Score'] = df.apply(compute_score, axis=1)\n",
    "top_resumes = df.sort_values(by=\"Quality Score\", ascending=False)\n",
    "top_resumes[['Filename', 'Quality Score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "def move_resumes_with_missing_name(source_directory, destination_directory):\n",
    "    # Ensure the destination directory exists\n",
    "    os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "    # Iterate through all JSON files in the source directory\n",
    "    for filename in os.listdir(source_directory):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(source_directory, filename)\n",
    "            try:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    json_data = json.load(file)\n",
    "                    # Check if the \"name\" field is missing or empty\n",
    "                    if not json_data.get(\"name\"):\n",
    "                        shutil.move(file_path, os.path.join(destination_directory, filename))\n",
    "                        print(f\"Moved: {filename}\")\n",
    "            except (json.JSONDecodeError, KeyError):\n",
    "                print(f\"Error reading file: {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    source_directory = \"/home/shtlp_0152/Desktop/project 1/data-ingestion-pipeline/data/standardized_resumes\"\n",
    "    destination_directory = \"/home/shtlp_0152/Desktop/project 1/data-ingestion-pipeline/data/missing_name_resumes\"\n",
    "    move_resumes_with_missing_name(source_directory, destination_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
